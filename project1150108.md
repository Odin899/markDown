# 臺北市私立薇閣高級中學114學年度第1學期工程專題
## 一、主題：
  深度學習-googlenet和teachable machine辨識圖片功能的比較
	goolenet是一個內建於matlab的神經網路模型，可以在matlab的一個叫做deep network designer裡找到它，它將捲積層、池化層、激活層等等視覺化，讓使用者能夠自行拖拽的方式修改模型，並且可以自行調整它的參數，也可以在程式碼輸入net=googlenet來呼叫已經訓練好的goolgenet模型。
	teachable machine 是由 Google 開發的一個網頁版免程式碼AI 訓練平台。它的設計是給低門檻的人使用，因此並沒有能夠自行修改模型的功能，它除了能夠用上傳圖片的方式，來收集和辨別影像，它也能夠結合攝像頭來去做影像的資料收集和辨識。
| 圖一、googlenet的架構圖 | 圖二、teachable machine的訓練流程圖 |
| :--- | :--- |
| <img width="500" height="944" alt="image" src="https://github.com/user-attachments/assets/8b777c90-2823-4d44-b24e-53897da8cf6c" /> | <img width="865" height="301" alt="image" src="https://github.com/user-attachments/assets/795f0de6-6ea9-44c4-b363-64eb556f1a26" /> |

## 二、收集資料：
  上網收集自己所需的圖片蘋果、香蕉、榴槤，並利用fatkun把大量的圖片一次性下載下來且規定只能是.png，因為matlab有支援，也防止下載到不支援的，之後分別裝入不同的資料夾，fatkun是一個chrome的擴充軟件，只要按幾下，就能夠下載整個網頁的圖片，不需要按令存新檔150次，省時又省力。
<details><summary>圖三、利用fatkun一次性下載50張apple的png圖片</summary><img width="865" height="409" alt="image" src="https://github.com/user-attachments/assets/0bec3052-82d3-4232-a01b-74b6b3ea16ae" /></details>
用XnView Classic 做批次傳換來調圖片大小和轉換成全彩圖，也是因為matlab有支援，以及批次重新命名來命名，讓資料看起來更整齊
<details><summary>圖四、用 XnView Classic將下載好的apple圖批次轉成全彩圖和227x227的大小</summary><img width="671" height="383" alt="image" src="https://github.com/user-attachments/assets/6f8a6036-a56c-408a-a95f-dc451bf6ebd7" />
</details>
<details><summary>圖五、用 XnView Classic將轉換好的圖批次命名為apple-##</summary><img width="719" height="398" alt="image" src="https://github.com/user-attachments/assets/0abfd489-c896-4a9f-a135-c10dddba5cf8" />
</details>
## 三、建立模型挖掘資料：
  利用googlenet的神經網路去做AI的模型訓練，一開始先把資料輸入進去，並且將圖形作一些間的改動讓這神經網路有更多不同的資料能夠做訓練
<details><summary>圖六、輸入資料的參數</summary><img width="711" height="358" alt="image" src="https://github.com/user-attachments/assets/c4e6adb3-65f8-4a4b-87df-74e6448de416" />
</details>
  在設計的部分，影像輸入時要將讀取尺寸換成以輸入資料的尺寸
<details><summary>圖七、改變能夠讀取圖片大小</summary><img width="460" height="446" alt="image" src="https://github.com/user-attachments/assets/891724ca-2479-4b5d-b536-2f89e95faea4" />
</details>
  再捲基層的地方也要把資料的輸出大小改成以輸入資料的種類
<details><summary>圖八、將卷積層的輸出大小改為五</summary><img width="450" height="525" alt="image" src="https://github.com/user-attachments/assets/3315c323-431d-4670-af4d-bbb4ad1d2dd5" />
</details>
  在輸出的時候也把它改成自動
<details><summary>圖九、將輸出大小自動</summary><img width="451" height="280" alt="image" src="https://github.com/user-attachments/assets/06295fdd-5a66-4bba-9f6a-1659164e004d" />
</details>
  在訓練時要把用來訓練用資料訂為小於等於訓練資料否則沒意義。
而teachable machine也是google的訓練模型，而它有規定圖片只能是224x224的全彩圖，不像matlab的可以在設計的地方自訂大小。
<details><summary> 圖十、teachable machine的規定</summary><img width="648" height="378" alt="image" src="https://github.com/user-attachments/assets/66f529b8-5bdd-4fc1-a02e-3c5ca28a6e7a" />
</details>

## 四、實驗結果:
I = imread("istockphoto-479186714-612x612.jpg");  讀取要判斷的圖片，並存入變數 I<br>
I = imresize(I, [227 227]);	調整讀取之圖片成227x227的大小<br>
[YPred,probs] = classify(trainedNetwork_1,I);    使用剛訓練完的模型並對I進行分類，分成[預測的類    別標籤,認為為該種類的機率]<br>
imshow(I);  顯示圖片I<br>
label = YPred;  將YPred存入，label的變數(方便後續字串處理)<br>
title(string(label) + ", " + num2str(100*max(probs),3) + "%");  將標籤轉成字串，用逗號隔開並從機率中找出最大的那個數值，轉成百分比，將數值轉為字串，並保留 3 位有效數字，將字串連接起來，格式為 “類別, 機率%”<br>
<details><summary>圖十一、googlenet的訓練圖</summary><img width="865" height="388" alt="image" src="https://github.com/user-attachments/assets/ce0fd1ef-6de0-4bb6-9324-b96ec38f5b22" />
</details>
<details><summary>圖十二、googlenet的訓練參數</summary><img width="555" height="644" alt="image" src="https://github.com/user-attachments/assets/c8d21459-0fc7-4a94-b3b4-1a2a99e146e5" />
</details>
<details><summary>圖十三、用來訓練googlenet資料的參數</summary><img width="865" height="431" alt="image" src="https://github.com/user-attachments/assets/9d7955c4-91f1-4ad1-b531-beb073c15af1" />
</details>
<details><summary>圖十四、teachable machine的訓練頁面</summary><img width="865" height="408" alt="image" src="https://github.com/user-attachments/assets/0b042ff1-52d1-4f33-9926-f97807640cd3" />
</details>
<details><summary>圖十五、teachable machine的訓練參數</summary><img width="335" height="569" alt="image" src="https://github.com/user-attachments/assets/b653467c-d34f-43b8-9f0b-195f1434c064" />
</details>
<details><summary>圖十六、googlenet的檢測結果(左)和teachable machine的檢結果(右)</summary><img width="538" height="307" alt="image" src="https://github.com/user-attachments/assets/f4baa470-c040-4757-8c52-5621601f20be" />
</details>

## 五、實驗結果討論
  在最後卷積層的的地方要把輸出大小改成未給她的資料大小否則會出現錯誤，那是因為神經網路架模型預期的數量，與實際提供的訓練資料的數量不一致，所以要回去設計模型的地方，找到那個卷積層，並將輸出大小改為5。
<img width="690" height="285" alt="image" src="https://github.com/user-attachments/assets/312e5b91-650b-4f96-99b9-2f96b17b7ded" /><br>
圖十七、所得資料和輸出資料不同的問題<br>
  另外，在比較googlenet和teachable machine的時候，發現teachable machine的辨識的能力比較準確，其中的原因可能是我在使用googlenet是比較老的模型，而teachable machine則是比較新的，再來可能是googlenet是把要判斷的圖片硬壓成224x224的正方形，而teachable machine則是置中裁切成正方形，然後再縮放。這樣做的好處是，物體的比例不會變形。
<img width="705" height="396" alt="image" src="https://github.com/user-attachments/assets/0b14fa0e-92ca-4802-85c2-a3a415b14bf5" /><br>
 圖十八、googlenet(左)和teachable machine(右)比較<br>

## 六、心得感想
  之前在使用AI的時候，從來沒有想過有天能夠自己去訓練能夠判斷自己想判斷的圖片，以及調整訓練時的參數，使訓練出來的模型精準度不同，也認識了許多不同種的神經網路模型，例如squeeznet、googlenet等等，和要在模型設計的地方需要注意哪邊的數值要改，例如一開始讀取圖片的大小，卷積層的輸出數值，以及最後的輸出大小改為自動，也知到AI不會把所有的資料都拿去做訓練，而是留下一些來考自己，比例通常是7:3，總之，能夠動手做AI是個特別的體驗。
